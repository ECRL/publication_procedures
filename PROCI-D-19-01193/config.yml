---
batch_size: 32
beta_1: 0.9
beta_2: 0.999
decay: 0.0
epochs: 3000
epsilon: 1.0e-07
hidden_layers:
- - 750
  - relu
- - 375
  - relu
- - 188
  - relu
- - 94
  - relu
learning_rate: 0.001
output_activation: linear
