{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391 545 385 205 43 255\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from ecnet.datasets import load_cp\n",
    "\n",
    "def get_property(compounds: list, property: str, lim: int = None) -> tuple:\n",
    "\n",
    "    prop_vals = []\n",
    "    smiles = []\n",
    "    for c in compounds:\n",
    "        try:\n",
    "            _val = [float(c['properties'][property]['value'])]\n",
    "        except KeyError:\n",
    "            continue\n",
    "        if lim is not None:\n",
    "            if _val[0] > lim:\n",
    "                continue\n",
    "        prop_vals.append(_val)\n",
    "        smiles.append(c['canonical_smiles'])\n",
    "    return (prop_vals, smiles)\n",
    "\n",
    "\n",
    "with open('compounds.json', 'r') as jfile:\n",
    "    compounds = json.load(jfile)\n",
    "jfile.close()\n",
    "\n",
    "cn, smiles_cn = get_property(compounds, 'cetane_number', 100)\n",
    "ysi, smiles_ysi = get_property(compounds, 'ysi_unified')\n",
    "lhv, smiles_lhv = get_property(compounds, 'lower_heating_value')\n",
    "kv, smiles_kv = get_property(compounds, 'kinematic_viscosity')\n",
    "smiles_cp, cp = load_cp()\n",
    "fp, smiles_fp = get_property(compounds, 'flash_point')\n",
    "\n",
    "print(len(cn), len(ysi), len(lhv), len(kv), len(cp), len(fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cn_train, cn_test, smiles_cn_train, smiles_cn_test = train_test_split(cn, smiles_cn, test_size=0.2, random_state=42)\n",
    "ysi_train, ysi_test, smiles_ysi_train, smiles_ysi_test = train_test_split(ysi, smiles_ysi, test_size=0.2, random_state=42)\n",
    "lhv_train, lhv_test, smiles_lhv_train, smiles_lhv_test = train_test_split(lhv, smiles_lhv, test_size=0.2, random_state=42)\n",
    "kv_train, kv_test, smiles_kv_train, smiles_kv_test = train_test_split(kv, smiles_kv, test_size=0.2, random_state=42)\n",
    "cp_train, cp_test, smiles_cp_train, smiles_cp_test = train_test_split(cp, smiles_cp, test_size=0.2, random_state=42)\n",
    "fp_train, fp_test, smiles_fp_train, smiles_fp_test = train_test_split(fp, smiles_fp, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ecnet.datasets import QSPRDataset\n",
    "\n",
    "ds_cn_train = QSPRDataset(smiles_cn_train, cn_train, backend='alvadesc')\n",
    "ds_cn_test = QSPRDataset(smiles_cn_test, cn_test, backend='alvadesc')\n",
    "\n",
    "ds_ysi_train = QSPRDataset(smiles_ysi_train, ysi_train, backend='alvadesc')\n",
    "ds_ysi_test = QSPRDataset(smiles_ysi_test, ysi_test, backend='alvadesc')\n",
    "\n",
    "ds_lhv_train = QSPRDataset(smiles_lhv_train, lhv_train, backend='alvadesc')\n",
    "ds_lhv_test = QSPRDataset(smiles_lhv_test, lhv_test, backend='alvadesc')\n",
    "\n",
    "ds_kv_train = QSPRDataset(smiles_kv_train, kv_train, backend='alvadesc')\n",
    "ds_kv_test = QSPRDataset(smiles_kv_test, kv_test, backend='alvadesc')\n",
    "\n",
    "ds_cp_train = QSPRDataset(smiles_cp_train, cp_train, backend='alvadesc')\n",
    "ds_cp_test = QSPRDataset(smiles_cp_test, cp_test, backend='alvadesc')\n",
    "\n",
    "ds_fp_train = QSPRDataset(smiles_fp_train, fp_train, backend='alvadesc')\n",
    "ds_fp_test = QSPRDataset(smiles_fp_test, fp_test, backend='alvadesc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([312, 661])\n",
      "torch.Size([436, 303])\n",
      "torch.Size([164, 568])\n",
      "torch.Size([34, 195])\n",
      "torch.Size([308, 101])\n",
      "torch.Size([204, 745])\n"
     ]
    }
   ],
   "source": [
    "from ecnet.tasks import select_rfr\n",
    "\n",
    "idx_cn, _ = select_rfr(ds_cn_train, 0.99, n_estimators=100)\n",
    "idx_ysi, _ = select_rfr(ds_ysi_train, 0.99, n_estimators=100)\n",
    "idx_kv, _ = select_rfr(ds_kv_train, 0.99, n_estimators=100)\n",
    "idx_cp, _ = select_rfr(ds_cp_train, 0.99, n_estimators=100)\n",
    "idx_lhv, _ = select_rfr(ds_lhv_train, 0.99, n_estimators=100)\n",
    "idx_fp, _ = select_rfr(ds_fp_train, 0.99, n_estimators=100)\n",
    "\n",
    "ds_cn_train.set_desc_index(idx_cn)\n",
    "ds_cn_test.set_desc_index(idx_cn)\n",
    "\n",
    "ds_ysi_train.set_desc_index(idx_ysi)\n",
    "ds_ysi_test.set_desc_index(idx_ysi)\n",
    "\n",
    "ds_kv_train.set_desc_index(idx_kv)\n",
    "ds_kv_test.set_desc_index(idx_kv)\n",
    "\n",
    "ds_cp_train.set_desc_index(idx_cp)\n",
    "ds_cp_test.set_desc_index(idx_cp)\n",
    "\n",
    "ds_lhv_train.set_desc_index(idx_lhv)\n",
    "ds_lhv_test.set_desc_index(idx_lhv)\n",
    "\n",
    "ds_fp_train.set_desc_index(idx_fp)\n",
    "ds_fp_test.set_desc_index(idx_fp)\n",
    "\n",
    "print(ds_cn_train.desc_vals.shape)\n",
    "print(ds_ysi_train.desc_vals.shape)\n",
    "print(ds_kv_train.desc_vals.shape)\n",
    "print(ds_cp_train.desc_vals.shape)\n",
    "print(ds_lhv_train.desc_vals.shape)\n",
    "print(ds_fp_train.desc_vals.shape)\n",
    "\n",
    "with open('models/cn/desc.txt', 'w', encoding='utf8') as f:\n",
    "    f.writelines([str(i) + '\\n' for i in idx_cn])\n",
    "f.close()\n",
    "with open('models/ysi/desc.txt', 'w', encoding='utf8') as f:\n",
    "    f.writelines([str(i) + '\\n' for i in idx_ysi])\n",
    "f.close()\n",
    "with open('models/kv/desc.txt', 'w', encoding='utf8') as f:\n",
    "    f.writelines([str(i) + '\\n' for i in idx_kv])\n",
    "f.close()\n",
    "with open('models/cp/desc.txt', 'w', encoding='utf8') as f:\n",
    "    f.writelines([str(i) + '\\n' for i in idx_cp])\n",
    "f.close()\n",
    "with open('models/lhv/desc.txt', 'w', encoding='utf8') as f:\n",
    "    f.writelines([str(i) + '\\n' for i in idx_lhv])\n",
    "f.close()\n",
    "with open('models/fp/desc.txt', 'w', encoding='utf8') as f:\n",
    "    f.writelines([str(i) + '\\n' for i in idx_fp])\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN 0...\n",
      "YSI 0...\n",
      "KV 0...\n",
      "CP 0...\n",
      "LHV 0...\n",
      "FP 0...\n",
      "CN 1...\n",
      "YSI 1...\n",
      "KV 1...\n",
      "CP 1...\n",
      "LHV 1...\n",
      "FP 1...\n",
      "CN 2...\n",
      "YSI 2...\n",
      "KV 2...\n",
      "CP 2...\n",
      "LHV 2...\n",
      "FP 2...\n",
      "CN 3...\n",
      "YSI 3...\n",
      "KV 3...\n",
      "CP 3...\n",
      "LHV 3...\n",
      "FP 3...\n",
      "CN 4...\n",
      "YSI 4...\n",
      "KV 4...\n",
      "CP 4...\n",
      "LHV 4...\n",
      "FP 4...\n",
      "CN 5...\n",
      "YSI 5...\n",
      "KV 5...\n",
      "CP 5...\n",
      "LHV 5...\n",
      "FP 5...\n",
      "CN 6...\n",
      "YSI 6...\n",
      "KV 6...\n",
      "CP 6...\n",
      "LHV 6...\n",
      "FP 6...\n",
      "CN 7...\n",
      "YSI 7...\n",
      "KV 7...\n",
      "CP 7...\n",
      "LHV 7...\n",
      "FP 7...\n",
      "CN 8...\n",
      "YSI 8...\n",
      "KV 8...\n",
      "CP 8...\n",
      "LHV 8...\n",
      "FP 8...\n",
      "CN 9...\n",
      "YSI 9...\n",
      "KV 9...\n",
      "CP 9...\n",
      "LHV 9...\n",
      "FP 9...\n",
      "CN 10...\n",
      "YSI 10...\n",
      "KV 10...\n",
      "CP 10...\n",
      "LHV 10...\n",
      "FP 10...\n",
      "CN 11...\n",
      "YSI 11...\n",
      "KV 11...\n",
      "CP 11...\n",
      "LHV 11...\n",
      "FP 11...\n",
      "CN 12...\n",
      "YSI 12...\n",
      "KV 12...\n",
      "CP 12...\n",
      "LHV 12...\n",
      "FP 12...\n",
      "CN 13...\n",
      "YSI 13...\n",
      "KV 13...\n",
      "CP 13...\n",
      "LHV 13...\n",
      "FP 13...\n",
      "CN 14...\n",
      "YSI 14...\n",
      "KV 14...\n",
      "CP 14...\n",
      "LHV 14...\n",
      "FP 14...\n",
      "CN 15...\n",
      "YSI 15...\n",
      "KV 15...\n",
      "CP 15...\n",
      "LHV 15...\n",
      "FP 15...\n",
      "CN 16...\n",
      "YSI 16...\n",
      "KV 16...\n",
      "CP 16...\n",
      "LHV 16...\n",
      "FP 16...\n",
      "CN 17...\n",
      "YSI 17...\n",
      "KV 17...\n",
      "CP 17...\n",
      "LHV 17...\n",
      "FP 17...\n",
      "CN 18...\n",
      "YSI 18...\n",
      "KV 18...\n",
      "CP 18...\n",
      "LHV 18...\n",
      "FP 18...\n",
      "CN 19...\n",
      "YSI 19...\n",
      "KV 19...\n",
      "CP 19...\n",
      "LHV 19...\n",
      "FP 19...\n",
      "CN 20...\n",
      "YSI 20...\n",
      "KV 20...\n",
      "CP 20...\n",
      "LHV 20...\n",
      "FP 20...\n",
      "CN 21...\n",
      "YSI 21...\n",
      "KV 21...\n",
      "CP 21...\n",
      "LHV 21...\n",
      "FP 21...\n",
      "CN 22...\n",
      "YSI 22...\n",
      "KV 22...\n",
      "CP 22...\n",
      "LHV 22...\n",
      "FP 22...\n",
      "CN 23...\n",
      "YSI 23...\n",
      "KV 23...\n",
      "CP 23...\n",
      "LHV 23...\n",
      "FP 23...\n",
      "CN 24...\n",
      "YSI 24...\n",
      "KV 24...\n",
      "CP 24...\n",
      "LHV 24...\n",
      "FP 24...\n"
     ]
    }
   ],
   "source": [
    "from ecnet import ECNet\n",
    "from sklearn.metrics import median_absolute_error, r2_score\n",
    "\n",
    "mae_cn = []\n",
    "mae_ysi = []\n",
    "mae_kv = []\n",
    "mae_cp = []\n",
    "mae_lhv = []\n",
    "mae_fp = []\n",
    "\n",
    "r2_cn = []\n",
    "r2_ysi = []\n",
    "r2_kv = []\n",
    "r2_cp = []\n",
    "r2_lhv = []\n",
    "r2_fp = []\n",
    "\n",
    "\n",
    "for i in range(25):\n",
    "\n",
    "    _model_cn = ECNet(ds_cn_train.desc_vals.shape[1], ds_cn_train.target_vals.shape[1], 512, 2)\n",
    "    _model_ysi = ECNet(ds_ysi_train.desc_vals.shape[1], ds_ysi_train.target_vals.shape[1], 512, 2)\n",
    "    _model_kv = ECNet(ds_kv_train.desc_vals.shape[1], ds_kv_train.target_vals.shape[1], 512, 2)\n",
    "    _model_cp = ECNet(ds_cp_train.desc_vals.shape[1], ds_cp_train.target_vals.shape[1], 512, 2)\n",
    "    _model_lhv = ECNet(ds_lhv_train.desc_vals.shape[1], ds_lhv_train.target_vals.shape[1], 512, 2)\n",
    "    _model_fp = ECNet(ds_fp_train.desc_vals.shape[1], ds_fp_train.target_vals.shape[1], 512, 2)\n",
    "\n",
    "    print(f'CN {i}...')\n",
    "    _model_cn.fit(\n",
    "        dataset=ds_cn_train,\n",
    "        epochs=512,\n",
    "        valid_size=0.33,\n",
    "        shuffle=True,\n",
    "        random_state=None,\n",
    "        batch_size=32,\n",
    "        patience=32,\n",
    "        lr=0.001\n",
    "    )\n",
    "    print(f'YSI {i}...')\n",
    "    _model_ysi.fit(\n",
    "        dataset=ds_ysi_train,\n",
    "        epochs=512,\n",
    "        valid_size=0.33,\n",
    "        shuffle=True,\n",
    "        random_state=None,\n",
    "        batch_size=32,\n",
    "        patience=32,\n",
    "        lr=0.001\n",
    "    )\n",
    "    print(f'KV {i}...')\n",
    "    _model_kv.fit(\n",
    "        dataset=ds_kv_train,\n",
    "        epochs=512,\n",
    "        valid_size=0.33,\n",
    "        shuffle=True,\n",
    "        random_state=None,\n",
    "        batch_size=16,\n",
    "        patience=32,\n",
    "        lr=0.001\n",
    "    )\n",
    "    print(f'CP {i}...')\n",
    "    _model_cp.fit(\n",
    "        dataset=ds_cp_train,\n",
    "        epochs=512,\n",
    "        valid_size=0.33,\n",
    "        shuffle=True,\n",
    "        random_state=None,\n",
    "        batch_size=4,\n",
    "        patience=32,\n",
    "        lr=0.001\n",
    "    )\n",
    "    print(f'LHV {i}...')\n",
    "    _model_lhv.fit(\n",
    "        dataset=ds_lhv_train,\n",
    "        epochs=512,\n",
    "        valid_size=0.33,\n",
    "        shuffle=True,\n",
    "        random_state=None,\n",
    "        batch_size=32,\n",
    "        patience=32,\n",
    "        lr=0.001\n",
    "    )\n",
    "    print(f'FP {i}...')\n",
    "    _model_fp.fit(\n",
    "        dataset=ds_fp_train,\n",
    "        epochs=512,\n",
    "        valid_size=0.33,\n",
    "        shuffle=True,\n",
    "        random_state=None,\n",
    "        batch_size=32,\n",
    "        patience=32,\n",
    "        lr=0.001\n",
    "    )\n",
    "\n",
    "    pred_cn = _model_cn(ds_cn_test.desc_vals).detach().numpy()\n",
    "    pred_ysi = _model_ysi(ds_ysi_test.desc_vals).detach().numpy()\n",
    "    pred_kv = _model_kv(ds_kv_test.desc_vals).detach().numpy()\n",
    "    pred_cp = _model_cp(ds_cp_test.desc_vals).detach().numpy()\n",
    "    pred_lhv = _model_lhv(ds_lhv_test.desc_vals).detach().numpy()\n",
    "    pred_fp = _model_fp(ds_fp_test.desc_vals).detach().numpy()\n",
    "\n",
    "    mae_cn.append(median_absolute_error(cn_test, pred_cn))\n",
    "    mae_ysi.append(median_absolute_error(ysi_test, pred_ysi))\n",
    "    mae_kv.append(median_absolute_error(kv_test, pred_kv))\n",
    "    mae_cp.append(median_absolute_error(cp_test, pred_cp))\n",
    "    mae_lhv.append(median_absolute_error(lhv_test, pred_lhv))\n",
    "    mae_fp.append(median_absolute_error(fp_test, pred_fp))\n",
    "\n",
    "    r2_cn.append(r2_score(cn_test, pred_cn))\n",
    "    r2_ysi.append(r2_score(ysi_test, pred_ysi))\n",
    "    r2_kv.append(r2_score(kv_test, pred_kv))\n",
    "    r2_cp.append(r2_score(cp_test, pred_cp))\n",
    "    r2_lhv.append(r2_score(lhv_test, pred_lhv))\n",
    "    r2_fp.append(r2_score(fp_test, pred_fp))\n",
    "\n",
    "    _model_cn.save(f'models/cn/cn_{i}.pt')\n",
    "    _model_ysi.save(f'models/ysi/ysi_{i}.pt')\n",
    "    _model_kv.save(f'models/kv/kv_{i}.pt')\n",
    "    _model_cp.save(f'models/cp/cp_{i}.pt')\n",
    "    _model_lhv.save(f'models/lhv/lhv_{i}.pt')\n",
    "    _model_fp.save(f'models/fp/fp_{i}.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN MAE: 4.994 +/- 0.911\n",
      "CN R2: 0.881 +/- 0.026\n",
      "YSI MAE: 6.020 +/- 1.555\n",
      "YSI R2: 0.959 +/- 0.061\n",
      "KV MAE: 0.073 +/- 0.032\n",
      "KV R2: 0.926 +/- 0.041\n",
      "CP MAE: 5.822 +/- 3.465\n",
      "CP R2: 0.842 +/- 0.093\n",
      "LHV MAE: 0.704 +/- 0.208\n",
      "LHV R2: 0.982 +/- 0.005\n",
      "FP MAE: 8.383 +/- 2.095\n",
      "FP R2: 0.899 +/- 0.029\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(f'CN MAE: {np.mean(mae_cn):.3f} +/- {np.std(mae_cn):.3f}')\n",
    "print(f'CN R2: {np.mean(r2_cn):.3f} +/- {np.std(r2_cn):.3f}')\n",
    "\n",
    "print(f'YSI MAE: {np.mean(mae_ysi):.3f} +/- {np.std(mae_ysi):.3f}')\n",
    "print(f'YSI R2: {np.mean(r2_ysi):.3f} +/- {np.std(r2_ysi):.3f}')\n",
    "\n",
    "print(f'KV MAE: {np.mean(mae_kv):.3f} +/- {np.std(mae_kv):.3f}')\n",
    "print(f'KV R2: {np.mean(r2_kv):.3f} +/- {np.std(r2_kv):.3f}')\n",
    "\n",
    "print(f'CP MAE: {np.mean(mae_cp):.3f} +/- {np.std(mae_cp):.3f}')\n",
    "print(f'CP R2: {np.mean(r2_cp):.3f} +/- {np.std(r2_cp):.3f}')\n",
    "\n",
    "print(f'LHV MAE: {np.mean(mae_lhv):.3f} +/- {np.std(mae_lhv):.3f}')\n",
    "print(f'LHV R2: {np.mean(r2_lhv):.3f} +/- {np.std(r2_lhv):.3f}')\n",
    "\n",
    "print(f'FP MAE: {np.mean(mae_fp):.3f} +/- {np.std(mae_fp):.3f}')\n",
    "print(f'FP R2: {np.mean(r2_fp):.3f} +/- {np.std(r2_fp):.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('ecnet')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "252b69efb517be662a91ca74889611414461adefdc1b62e7a9ebf1bc6024e96f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
